{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gG1jLtuIUD9X",
      "metadata": {
        "id": "gG1jLtuIUD9X"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4469de0d-c177-4c70-bd61-997abf0d2413",
      "metadata": {
        "id": "4469de0d-c177-4c70-bd61-997abf0d2413"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-2/L2_colab_prompting_and_parameters.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a78497-e504-438d-9420-3bf501d4dd80",
      "metadata": {
        "id": "39a78497-e504-438d-9420-3bf501d4dd80"
      },
      "source": [
        "# Cost Estimate\n",
        "\n",
        "The estimated cost for running this notebook once using your Google Cloud account, without the video segment (which has been converted to markdown), should be less than 0.10 USD (as of August 2024). Get the latest Gemini costs [here](https://cloud.google.com/vertex-ai/generative-ai/pricing).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z7zgKCZtGpZ4",
      "metadata": {
        "id": "Z7zgKCZtGpZ4"
      },
      "source": [
        "# SETUP\n",
        "\n",
        "This is follow up to the [How to Set Up your Google Cloud Account](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/9/how-to-set-up-your-google-cloud-account-|-try-it-out-yourself-[optional]) instructions from the course, [Large Multimodal Model Prompting with Gemini](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/1/introduction) on the [Learning Platform](https://learn.deeplearning.ai) of [DeepLearning.AI](https://www.deeplearning.ai)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wHqB_Oj_UJk8",
      "metadata": {
        "id": "wHqB_Oj_UJk8"
      },
      "source": [
        "### Install Vertex AI SDK and other Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vL4hB1oVUNDQ",
      "metadata": {
        "id": "vL4hB1oVUNDQ"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CHi-tyTmUOio",
      "metadata": {
        "id": "CHi-tyTmUOio"
      },
      "source": [
        "### Restart Runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "UaeJM15OUQ2P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaeJM15OUQ2P",
        "outputId": "a84cc83e-3ed9-4526-8608-aeac4a4e5631"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cSMxj27UU52X",
      "metadata": {
        "id": "cSMxj27UU52X"
      },
      "source": [
        "### Authenticate your Notebook Environment (Colab Only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment.\n",
        "\n",
        "**NOTE:** The Gmail email address you use to authenticate this lesson colab must be the same as the one you used to set up your Google Cloud account and your Project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f_n81JzjU6Ry",
      "metadata": {
        "id": "f_n81JzjU6Ry"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TUULXAEvUp_M",
      "metadata": {
        "id": "TUULXAEvUp_M"
      },
      "source": [
        "### Set Google Cloud Project Information and Initialize Vertex AI SDK\n",
        "\n",
        "**Add _your_ Project ID below**, which you created while following the [How to Set Up your Google Cloud Account](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/9/how-to-set-up-your-google-cloud-account-|-try-it-out-yourself-[optional]) instructions. If your `Project ID` was `dlai-shortcourse-on-gemini`, then you can run the cell below as it is. Otherwise, be sure to change it.\n",
        "\n",
        "You can also look up your Project ID in your [Project Dashboard](https://console.cloud.google.com/projectselector2/home/dashboard)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "FjTRgq1gUqr7",
      "metadata": {
        "id": "FjTRgq1gUqr7"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"dlai-shortcourse-on-gemini\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9jAM5fkqR2MQ",
      "metadata": {
        "id": "9jAM5fkqR2MQ"
      },
      "source": [
        "### Utils Functions and Images\n",
        "\n",
        "**Important Note:**\n",
        "\n",
        "If using Google Colab, all the\n",
        "```Python\n",
        "from utils import ...\n",
        "```\n",
        "\n",
        "functions and all required images are readily accessible in the notebook. Execute the following cells to proceed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fMOijj8mRiBm",
      "metadata": {
        "id": "fMOijj8mRiBm"
      },
      "outputs": [],
      "source": [
        "import typing\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    Image,\n",
        ")\n",
        "\n",
        "def gemini(prompt, model):\n",
        "    responses = model.generate_content(prompt,\n",
        "                                     stream=True)\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text\n",
        "\n",
        "    return response_text\n",
        "\n",
        "def display_images(\n",
        "    images: typing.Iterable[Image],\n",
        "    max_width: int = 600,\n",
        "    max_height: int = 350,\n",
        ") -> None:\n",
        "    for image in images:\n",
        "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "        if pil_image.mode != \"RGB\":\n",
        "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
        "            pil_image = pil_image.convert(\"RGB\")\n",
        "        image_width, image_height = pil_image.size\n",
        "        if max_width < image_width or max_height < image_height:\n",
        "            # Resize to display a smaller notebook image\n",
        "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "        IPython.display.display(pil_image)\n",
        "\n",
        "def print_multimodal_prompt(contents: list):\n",
        "    \"\"\"\n",
        "    Given contents that would be sent to Gemini,\n",
        "    output the full multimodal prompt for ease of readability.\n",
        "    \"\"\"\n",
        "    for content in contents:\n",
        "        if isinstance(content, Image):\n",
        "            display_images([content])\n",
        "        elif isinstance(content, Part):\n",
        "            url = get_url_from_gcs(content.file_data.file_uri)\n",
        "            IPython.display.display(load_image_from_url(url))\n",
        "        else:\n",
        "            print(content)\n",
        "\n",
        "def gemini_vision(contents_image, model):\n",
        "\n",
        "    responses = model.generate_content(\n",
        "        contents_image,\n",
        "        stream=True)\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text\n",
        "    return response_text\n",
        "\n",
        "def gemini_vision_parameters(contents_image, model, config):\n",
        "\n",
        "    responses = model.generate_content(\n",
        "        contents=contents_image,\n",
        "        generation_config=config,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    response_text = \"\"\n",
        "    for response in responses:\n",
        "        response_text += response.text\n",
        "\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ykzDUi1HSmh7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykzDUi1HSmh7",
        "outputId": "0ad9f655-c9b3-4e36-8b3e-c573572e48a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://dlai-sc-gemini-bucket/Andrew_power_tools.png...\n",
            "/ [1 files][710.5 KiB/710.5 KiB]                                                \n",
            "Operation completed over 1 objects/710.5 KiB.                                    \n",
            "Copying gs://dlai-sc-gemini-bucket/panda.png...\n",
            "/ [1 files][974.9 KiB/974.9 KiB]                                                \n",
            "Operation completed over 1 objects/974.9 KiB.                                    \n"
          ]
        }
      ],
      "source": [
        "# download images from bucket\n",
        "! gsutil cp \"gs://dlai-sc-gemini-bucket/Andrew_power_tools.png\" ./andrew_power_tools.png\n",
        "! gsutil cp \"gs://dlai-sc-gemini-bucket/panda.png\" ./panda.png"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TH6InE1eJFIo",
      "metadata": {
        "id": "TH6InE1eJFIo"
      },
      "source": [
        "# IN COURSE VIDEO\n",
        "\n",
        "Lesson video starts from below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c233b7-5638-4272-8a00-4d24b50a301c",
      "metadata": {
        "id": "25c233b7-5638-4272-8a00-4d24b50a301c"
      },
      "source": [
        "# [Lesson 2: Multimodal Prompting and Parameter Control](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/3/multimodal-prompting-and-parameter-control)\n",
        "\n",
        "In this notebook, you'll have a quick overview of simple text, image and video examples with Gemini, and learn about different Parameters which can be set up."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "840b7ec6-0398-449d-9b33-d155ed3bbc57",
      "metadata": {
        "id": "840b7ec6-0398-449d-9b33-d155ed3bbc57"
      },
      "source": [
        "## Text Examples\n",
        "\n",
        "- Load the [gemini-1.0-pro-002](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-pro) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "21beed65-dd33-488d-b693-5f22b85cbb3c",
      "metadata": {
        "id": "21beed65-dd33-488d-b693-5f22b85cbb3c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from vertexai.generative_models import GenerativeModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b801cd93-8f52-4169-a0a0-b407815bf315",
      "metadata": {
        "id": "b801cd93-8f52-4169-a0a0-b407815bf315"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro-002\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ee2af17b-6115-4588-a6c7-4714537c6538",
      "metadata": {
        "id": "ee2af17b-6115-4588-a6c7-4714537c6538",
        "tags": [],
        "outputId": "ed26c410-59a7-4573-cd6e-6c9be628395a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-168f91008f4e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from utils import gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d48211fa-caa9-4f1f-8f8e-3902da70fa3e",
      "metadata": {
        "id": "d48211fa-caa9-4f1f-8f8e-3902da70fa3e"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get.\n",
        "\n",
        "If you run the next cell and receive a `403 error`:\n",
        "\n",
        "\n",
        "*   Recheck your project name, and be sure it matches the name assigned when setting up the Google Cloud Project. Note that project names are lowercase.\n",
        "*   Ensure you completed Step 5 of the instructions on setting up Google Cloud and Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5d1e33-92ec-483d-876d-41b4fa8541bf",
      "metadata": {
        "id": "ec5d1e33-92ec-483d-876d-41b4fa8541bf"
      },
      "outputs": [],
      "source": [
        "gemini(\"What is a multimodal model?\", model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe619d8b-7e10-4919-98e7-86595e50af17",
      "metadata": {
        "id": "fe619d8b-7e10-4919-98e7-86595e50af17"
      },
      "source": [
        "#### Under the hood of the helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704861c4-c4f8-4543-b274-981be3f0535d",
      "metadata": {
        "id": "704861c4-c4f8-4543-b274-981be3f0535d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt_1 = \"\"\"\n",
        "In short, what is deeplearning.ai,\n",
        "and what can it offer me as a Machine Learning Engineer?\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74fe5991-312a-4cbc-afe7-3fbae00b4bfd",
      "metadata": {
        "id": "74fe5991-312a-4cbc-afe7-3fbae00b4bfd"
      },
      "source": [
        "- `stream=True` processes the response as it being generated.\n",
        "- With `stream=False`, you have to wait until the entire response has been generated before it can be proccessed and printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036f1093-edd4-45d5-941d-fdab191bfa3c",
      "metadata": {
        "id": "036f1093-edd4-45d5-941d-fdab191bfa3c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response_1 = model.generate_content(prompt_1, stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3389be82-a2a6-47cc-bec2-5faa72b4cb98",
      "metadata": {
        "id": "3389be82-a2a6-47cc-bec2-5faa72b4cb98",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f70cd229-f7ef-45a6-a5d6-63e2f5c28ea5",
      "metadata": {
        "id": "f70cd229-f7ef-45a6-a5d6-63e2f5c28ea5"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3355fda3-d28e-4117-bb28-39b23636c59a",
      "metadata": {
        "id": "3355fda3-d28e-4117-bb28-39b23636c59a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for response in response_1:\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1c66f5-1d31-4383-890a-ae6c7cb9b6a4",
      "metadata": {
        "id": "2d1c66f5-1d31-4383-890a-ae6c7cb9b6a4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response_1 = model.generate_content(prompt_1,\n",
        "                                     stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7678756-b8b5-4570-9c7d-18f4978cf247",
      "metadata": {
        "id": "e7678756-b8b5-4570-9c7d-18f4978cf247",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for response in response_1:\n",
        "    print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78640c5d-6853-43ab-9c15-b4ecf7d0d161",
      "metadata": {
        "id": "78640c5d-6853-43ab-9c15-b4ecf7d0d161"
      },
      "source": [
        "## Multimodality: Image + Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ebe7d2-c3de-4f5c-a28a-33660cc5c091",
      "metadata": {
        "id": "d5ebe7d2-c3de-4f5c-a28a-33660cc5c091",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    Image,\n",
        "    Part,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d03dd7-9ff2-4354-b4bc-33f9b38b23a7",
      "metadata": {
        "id": "36d03dd7-9ff2-4354-b4bc-33f9b38b23a7"
      },
      "source": [
        "- Load the [gemini-1.0-pro-vision-001](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-pro-vision) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7de679-4097-45c2-8f56-1bc4c1079927",
      "metadata": {
        "id": "be7de679-4097-45c2-8f56-1bc4c1079927"
      },
      "outputs": [],
      "source": [
        "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision-001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e78c835-2a20-4ae6-a6d6-f51620031237",
      "metadata": {
        "id": "7e78c835-2a20-4ae6-a6d6-f51620031237",
        "tags": []
      },
      "source": [
        "- Load a prompt and an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VfTYCwiwZ7P6",
      "metadata": {
        "id": "VfTYCwiwZ7P6"
      },
      "outputs": [],
      "source": [
        "image = Image.load_from_file(\"andrew_power_tools.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba405c7d-9de5-467b-b9d1-d5ce7c8fe239",
      "metadata": {
        "id": "ba405c7d-9de5-467b-b9d1-d5ce7c8fe239"
      },
      "outputs": [],
      "source": [
        "prompt_3 = \"Please describe what is in this image?\"\n",
        "\n",
        "# prompt_3 = \"What are likely professions of this person?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774f8528-0b84-44a1-8158-051f6f2bccff",
      "metadata": {
        "id": "774f8528-0b84-44a1-8158-051f6f2bccff"
      },
      "outputs": [],
      "source": [
        "contents_image = [image, prompt_3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0becf0c0-8cb7-4909-9f13-6908a036e80c",
      "metadata": {
        "id": "0becf0c0-8cb7-4909-9f13-6908a036e80c"
      },
      "outputs": [],
      "source": [
        "# from utils import print_multimodal_prompt\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9394627-7b0b-44fe-b244-cee15a8868cd",
      "metadata": {
        "id": "f9394627-7b0b-44fe-b244-cee15a8868cd"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b506f4c-a5d9-4cd0-bf2d-6b871d413ee5",
      "metadata": {
        "id": "0b506f4c-a5d9-4cd0-bf2d-6b871d413ee5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# from utils import gemini_vision\n",
        "\n",
        "gemini_vision(contents_image, model=multimodal_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d909defe-d44b-415a-955b-5f8aae197914",
      "metadata": {
        "id": "d909defe-d44b-415a-955b-5f8aae197914"
      },
      "source": [
        "## Multimodality: Video + Text\n",
        "\n",
        "- Load a video and a prompt.\n",
        "- The video loads from a GCP bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01494ed8-f28b-424d-95d6-c509b2dc8631",
      "metadata": {
        "id": "01494ed8-f28b-424d-95d6-c509b2dc8631",
        "tags": []
      },
      "outputs": [],
      "source": [
        "file_path = \"dlai-sc-gemini-bucket/pixel8.mp4\"\n",
        "video_uri = f\"gs://{file_path}\"\n",
        "video_url = f\"https://storage.googleapis.com/{file_path}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "046bdd4b-7b81-4180-84ed-cbefcaa28b32",
      "metadata": {
        "id": "046bdd4b-7b81-4180-84ed-cbefcaa28b32",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import IPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd77e98-e79f-40ff-a9a6-da24ee93ef9d",
      "metadata": {
        "id": "bfd77e98-e79f-40ff-a9a6-da24ee93ef9d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "IPython.display.Video(video_url, width=450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "277a1971-181b-4efc-aa96-300e6d94a673",
      "metadata": {
        "id": "277a1971-181b-4efc-aa96-300e6d94a673",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Answer the following questions using the video only:\n",
        " - What is the main person's profession?\n",
        " - What are the main features of the phone highlighted?\n",
        " - Which city was this recorded in?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "471ef7bd-7a5a-4c71-a371-3d2e6b3c4e48",
      "metadata": {
        "id": "471ef7bd-7a5a-4c71-a371-3d2e6b3c4e48",
        "tags": []
      },
      "outputs": [],
      "source": [
        "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")\n",
        "contents_video = [prompt, video]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3a8e31-6487-44c6-87d2-6f7b3dec721f",
      "metadata": {
        "id": "3f3a8e31-6487-44c6-87d2-6f7b3dec721f",
        "tags": []
      },
      "source": [
        "**Note:** This cell is converted to markdown to prevent accidentally executing it. The cost to run this cell is approximately 0.12 USD (as of August 2024).\n",
        "\n",
        "```Python\n",
        "responses_4 = multimodal_model.generate_content(contents_video, stream=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b97925d-99c3-47d4-bcac-30d500b64b8f",
      "metadata": {
        "id": "5b97925d-99c3-47d4-bcac-30d500b64b8f"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19751f79-0301-4b59-a097-285a919b9a56",
      "metadata": {
        "id": "19751f79-0301-4b59-a097-285a919b9a56",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for response in responses_4:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcfb4ce9-68e5-41ee-af56-b8161a91fd54",
      "metadata": {
        "id": "bcfb4ce9-68e5-41ee-af56-b8161a91fd54"
      },
      "source": [
        "## Gemini Model Parameters\n",
        "\n",
        "- Load an image.\n",
        "- You'll be using the [gemini-1.0-pro-vision-001](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-pro-vision) model.\n",
        "- First run the model using its _default parameters_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e64b9d-dcc7-4a48-bc74-835503849b50",
      "metadata": {
        "id": "34e64b9d-dcc7-4a48-bc74-835503849b50"
      },
      "outputs": [],
      "source": [
        "image_1 = Image.load_from_file(\"./panda.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a36d714-5176-4481-84dd-78951e7efc99",
      "metadata": {
        "id": "8a36d714-5176-4481-84dd-78951e7efc99"
      },
      "outputs": [],
      "source": [
        "prompt_1 = \"\"\"Write what is happening in the following image\n",
        "from a unique perspective and do not mention names\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03451d6-943c-4ef8-a334-dd44ed322105",
      "metadata": {
        "id": "e03451d6-943c-4ef8-a334-dd44ed322105"
      },
      "outputs": [],
      "source": [
        "contents = [image_1, prompt_1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a055ac9c-554a-4b27-a847-b308ed8ba109",
      "metadata": {
        "id": "a055ac9c-554a-4b27-a847-b308ed8ba109"
      },
      "outputs": [],
      "source": [
        "# from utils import print_multimodal_prompt\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a354685-b772-4e0d-8c32-a62d06e54395",
      "metadata": {
        "id": "6a354685-b772-4e0d-8c32-a62d06e54395"
      },
      "outputs": [],
      "source": [
        "response_1 = multimodal_model.generate_content(\n",
        "    contents,\n",
        "    stream=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52982b60-7d16-4433-bda5-7f4cba1647c3",
      "metadata": {
        "id": "52982b60-7d16-4433-bda5-7f4cba1647c3"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a344e6e3-d9dd-4b5c-9d92-2685dab4204f",
      "metadata": {
        "id": "a344e6e3-d9dd-4b5c-9d92-2685dab4204f"
      },
      "outputs": [],
      "source": [
        "for response in response_1:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946e8b33-aa99-4eea-8fdd-edbb21d7d55f",
      "metadata": {
        "id": "946e8b33-aa99-4eea-8fdd-edbb21d7d55f"
      },
      "source": [
        "### Temperature, Top k"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "261d04d9-d86f-4d53-a8bc-11b8388442af",
      "metadata": {
        "id": "261d04d9-d86f-4d53-a8bc-11b8388442af"
      },
      "source": [
        "- GenerationConfig lets you set up the parameters for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad41473c-24dc-46e2-bb94-4c09bc87c156",
      "metadata": {
        "id": "ad41473c-24dc-46e2-bb94-4c09bc87c156"
      },
      "source": [
        "**Note:** In the latest version, `from vertexai.preview.generative_models` has been changed to `from vertexai.generative_models`.\n",
        "\n",
        "`from vertexai.preview.generative_models` can still be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "813625a9-fe8f-4c0c-b8c3-cb10b5281543",
      "metadata": {
        "id": "813625a9-fe8f-4c0c-b8c3-cb10b5281543"
      },
      "outputs": [],
      "source": [
        "from vertexai.generative_models import GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd81c170-e93f-452b-aa35-6ca570532a97",
      "metadata": {
        "id": "cd81c170-e93f-452b-aa35-6ca570532a97"
      },
      "outputs": [],
      "source": [
        "# from utils import gemini_vision_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7322b205-6b77-4a02-b701-2994d5824f28",
      "metadata": {
        "id": "7322b205-6b77-4a02-b701-2994d5824f28"
      },
      "source": [
        "- Setting `temperature=0.0` and `top_k=1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "170dfac3-18db-40be-9200-b80a4b01842f",
      "metadata": {
        "id": "170dfac3-18db-40be-9200-b80a4b01842f"
      },
      "outputs": [],
      "source": [
        "generation_config_1 = GenerationConfig(\n",
        "    temperature=0.0,\n",
        "    top_k=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f490d6c-a180-445c-a043-161132db5f3c",
      "metadata": {
        "id": "7f490d6c-a180-445c-a043-161132db5f3c"
      },
      "outputs": [],
      "source": [
        "response_zero_temp = gemini_vision_parameters(\n",
        "                        contents,\n",
        "                        multimodal_model,\n",
        "                        generation_config_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4035577-b04c-443c-aa3b-74dfabddfac9",
      "metadata": {
        "id": "f4035577-b04c-443c-aa3b-74dfabddfac9"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae072df-d4f1-4481-9e31-848e55afd4d3",
      "metadata": {
        "id": "cae072df-d4f1-4481-9e31-848e55afd4d3"
      },
      "outputs": [],
      "source": [
        "print(response_zero_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4fafa4-23b5-4368-8f82-d850b4bfc84b",
      "metadata": {
        "id": "7d4fafa4-23b5-4368-8f82-d850b4bfc84b"
      },
      "outputs": [],
      "source": [
        "responses_zero_temp = gemini_vision_parameters(\n",
        "                        contents,\n",
        "                        multimodal_model,\n",
        "                        generation_config_1)\n",
        "\n",
        "print(response_zero_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e31865d-df02-4b04-a709-68da344e70dd",
      "metadata": {
        "id": "2e31865d-df02-4b04-a709-68da344e70dd"
      },
      "source": [
        "- Setting `temperature=1` and `top_k=40`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0921b47b-a859-4484-93e6-daa2023c7628",
      "metadata": {
        "id": "0921b47b-a859-4484-93e6-daa2023c7628"
      },
      "outputs": [],
      "source": [
        "generation_config_2 = GenerationConfig(\n",
        "    temperature=1,\n",
        "    top_k=40,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5393c843-722c-4caf-b49c-e2dcf4d374ef",
      "metadata": {
        "id": "5393c843-722c-4caf-b49c-e2dcf4d374ef"
      },
      "outputs": [],
      "source": [
        "responses_high_temp_topk = gemini_vision_parameters(\n",
        "                            contents,\n",
        "                            multimodal_model,\n",
        "                            generation_config_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ab9d799-5772-4e7a-a867-c79be6e672e7",
      "metadata": {
        "id": "1ab9d799-5772-4e7a-a867-c79be6e672e7"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c6d6a7-3514-4bd9-9f5a-c821188c4a14",
      "metadata": {
        "id": "e6c6d6a7-3514-4bd9-9f5a-c821188c4a14"
      },
      "outputs": [],
      "source": [
        "print(responses_high_temp_topk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2541d3a-f769-4bb5-9885-54f01a38070e",
      "metadata": {
        "id": "e2541d3a-f769-4bb5-9885-54f01a38070e"
      },
      "source": [
        "### Top p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f76e5e43-f8a5-4f66-ae43-ab2f46b05197",
      "metadata": {
        "id": "f76e5e43-f8a5-4f66-ae43-ab2f46b05197"
      },
      "source": [
        "- Setting `top_p=0.01`, and maintaining `temperature=1`, `top_k=40`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4dd785-171c-4027-9811-313dbe588de9",
      "metadata": {
        "id": "9a4dd785-171c-4027-9811-313dbe588de9"
      },
      "outputs": [],
      "source": [
        "generation_config_4 = GenerationConfig(\n",
        "    temperature=1,\n",
        "    top_k=40,\n",
        "    top_p=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2e26eb8-67ea-42af-8b7a-4fb5db46a0d6",
      "metadata": {
        "id": "c2e26eb8-67ea-42af-8b7a-4fb5db46a0d6"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1596c39-5dfb-4f9b-9a5f-63229077202c",
      "metadata": {
        "id": "f1596c39-5dfb-4f9b-9a5f-63229077202c"
      },
      "outputs": [],
      "source": [
        "responses_high_temp_topp = gemini_vision_parameters(\n",
        "                            contents,\n",
        "                            multimodal_model,\n",
        "                            generation_config_4)\n",
        "\n",
        "print(responses_high_temp_topp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5b6684-6a55-47cd-91ec-48574e6dfb2a",
      "metadata": {
        "id": "6d5b6684-6a55-47cd-91ec-48574e6dfb2a"
      },
      "source": [
        "### Max Output Tokens\n",
        "\n",
        "- The range for `max_output_tokens` is `1 (inclusive) to 2049 (exclusive)`\n",
        "- When using `max_output_tokens`, the number of words returned by the model are 1 less than what you specify.\n",
        "- So setting `max_output_tokens` to `1` will throw an error, since there would be no generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ba487f-948d-407b-a6ba-fe22d3605502",
      "metadata": {
        "id": "72ba487f-948d-407b-a6ba-fe22d3605502"
      },
      "outputs": [],
      "source": [
        "generation_config_5 = GenerationConfig(\n",
        "    max_output_tokens=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cc9d04a-986f-4747-b538-e636801f0a56",
      "metadata": {
        "id": "3cc9d04a-986f-4747-b538-e636801f0a56"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22e7d24-73c5-4229-b489-36ae24e5a575",
      "metadata": {
        "id": "e22e7d24-73c5-4229-b489-36ae24e5a575"
      },
      "outputs": [],
      "source": [
        "responses_max_output = gemini_vision_parameters(\n",
        "                        contents,\n",
        "                        multimodal_model,\n",
        "                        generation_config_5)\n",
        "\n",
        "print(responses_max_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6dafcb0-9f2b-4f1f-84dd-555a1954849c",
      "metadata": {
        "id": "e6dafcb0-9f2b-4f1f-84dd-555a1954849c"
      },
      "source": [
        "### Stop Sequences\n",
        "\n",
        "- The range for `stop_sequences` is `1 (inclusive) to 17 (exclusive)`\n",
        "- Multiple (no more than 16) words, numbers, space or special characters can be passed as a `list`.\n",
        "- The model response stops _just before_ the _first time_ it encounters any stop sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e79cad9-4428-4099-856a-584cddc6fa5a",
      "metadata": {
        "id": "7e79cad9-4428-4099-856a-584cddc6fa5a"
      },
      "outputs": [],
      "source": [
        "generation_config_6 = GenerationConfig(\n",
        "    stop_sequences=[\"panda\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb7a283-9a49-427a-912d-6b0ba535230e",
      "metadata": {
        "id": "0cb7a283-9a49-427a-912d-6b0ba535230e"
      },
      "source": [
        "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "585fa9c7-3790-4f88-af5a-07184c660346",
      "metadata": {
        "id": "585fa9c7-3790-4f88-af5a-07184c660346"
      },
      "outputs": [],
      "source": [
        "responses_stop = gemini_vision_parameters(\n",
        "                    contents,\n",
        "                    multimodal_model,\n",
        "                    generation_config_6)\n",
        "\n",
        "print(responses_stop)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-cpu.2-11.m114",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
    },
    "kernelspec": {
      "display_name": "gc-c4",
      "language": "python",
      "name": "gc-c4"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}